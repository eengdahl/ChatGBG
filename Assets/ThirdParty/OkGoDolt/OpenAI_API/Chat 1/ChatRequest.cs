using Newtonsoft.Json;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;

namespace OpenAI_API.Chat
{
	/// A request to the Chat API. This is similar, but not exactly the same as the  Completions.CompletionRequest 
	public class ChatRequest
	{
	
		[JsonProperty("model")]
		public string Model { get; set; } = OpenAI_API.Models.Model.ChatGPTTurbo;

		/// The messages to send with this Chat Request
		[JsonProperty("messages")]
		public IList<ChatMessage> Messages { get; set; }

		/// What sampling temperature to use 
		[JsonProperty("temperature")]
		public double? Temperature { get; set; }
		//Setup for json
		[JsonProperty("top_p")]
		public double? TopP { get; set; }
		
		[JsonProperty("n")]
		public int? NumChoicesPerMessage = 1;

		/// Specifies where the results should stream and be returned at one time. 
		//Do not set this yourself, use the appropriate methods on CompletionEndpoint instead.
		[JsonProperty("stream")]
		public bool Stream { get; internal set; } = false;

		/// This is only used for serializing the request into JSON, do not use it directly.
		[JsonProperty("stop")]
		internal object CompiledStop
		{
			get
			{
				if (MultipleStopSequences?.Length == 1)
					return StopSequence;
				else if (MultipleStopSequences?.Length > 0)
					return MultipleStopSequences;
				else
					return null;
			}
		}

		/// One or more sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
		[JsonIgnore]
		public string[] MultipleStopSequences { get; set; }

		/// The stop sequence where the API will stop generating further tokens. The returned text will not contain the stop sequence. 
		//For convenience, if you are only requesting a single stop sequence, set it here
		[JsonIgnore]
		public string StopSequence
		{
			get => MultipleStopSequences?.FirstOrDefault() ?? null;
			set
			{
				if (value != null)
					MultipleStopSequences = new string[] { value };
			}
		}

		/// How many tokens to complete to. Can return fewer if a stop sequence is hit.  Defaults to 16.
		[JsonProperty("max_tokens")]
		public int? MaxTokens { get; set; }

		/// The scale of the penalty for how often a token is used.  Should generally be between 0 and 1, 
		[JsonProperty("frequency_penalty")]
		public double? FrequencyPenalty { get; set; }


		/// The scale of the penalty applied if a token is already present at all.  
		[JsonProperty("presence_penalty")]
		public double? PresencePenalty { get; set; }

		/// Modify the likelihood of specified tokens appearing in the completion.
		/// Accepts a json object that maps tokens(specified by their token ID in the tokenizer) to an associated bias value from -100 to 100.
		/// Mathematically, the bias is added to the logits generated by the model prior to sampling.
		/// The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection
		[JsonProperty("logit_bias")]
		public IReadOnlyDictionary<string, float> LogitBias { get; set; }

		/// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
		[JsonProperty("user")]
		public string user { get; set; }

        /// Creates a new, empty ChatRequest
        public ChatRequest()
		{ }

        /// Create a new chat request using the data from the input chat request.
        public ChatRequest(ChatRequest basedOn)
		{
			if (basedOn == null)
				return;

			this.Model = basedOn.Model;
			this.Messages = basedOn.Messages;
			this.Temperature = basedOn.Temperature;
			this.TopP = basedOn.TopP;
			this.NumChoicesPerMessage = basedOn.NumChoicesPerMessage;
			this.MultipleStopSequences = basedOn.MultipleStopSequences;
			this.MaxTokens = basedOn.MaxTokens;
			this.FrequencyPenalty = basedOn.FrequencyPenalty;
			this.PresencePenalty = basedOn.PresencePenalty;
			this.LogitBias = basedOn.LogitBias;
		}
	}
}
